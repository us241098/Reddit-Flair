{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import string\n",
    "fields = ['title', 'selftext', 'flair']\n",
    "\n",
    "df = pd.read_csv('reddit_with_flairs.csv', skipinitialspace=True, usecols=fields)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205363, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.fillna(\" \")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205142, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['title'].str.split().str.len().lt(55)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203541, 3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['selftext'].str.split().str.len().lt(400)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You all, cannot'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTRACTION_MAP = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "    \n",
    "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                      flags=re.IGNORECASE|re.DOTALL)\n",
    "    def expand_match(contraction):\n",
    "        match = contraction.group(0)\n",
    "        first_char = match[0]\n",
    "        expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                if contraction_mapping.get(match)\\\n",
    "                                else contraction_mapping.get(match.lower())                       \n",
    "        expanded_contraction = first_char+expanded_contraction[1:]\n",
    "        return expanded_contraction\n",
    "        \n",
    "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "    return expanded_text\n",
    "\n",
    "expand_contractions(\"Y'all, can't\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203541, 4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"] = df[\"title\"] + df[\"selftext\"]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df['text'].apply(lambda x : remove_punct(x))\n",
    "df['text']=df['text'].apply(lambda x : remove_html(x))\n",
    "df['text']=df['text'].apply(lambda x : remove_URL(x))\n",
    "df['text']=df['text'].apply(lambda x : remove_emoji(x))\n",
    "df['text']=df['text'].apply(lambda x : expand_contractions(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Crocodile in water tiger on land Humans Gays a...\n",
       "1         Samsung Galaxy S9 Will launch Next Month At MW...\n",
       "2         Exposed Kerala madrasas teaching Wahabism Saud...\n",
       "3         How can we start a small service provider firm...\n",
       "4         Fsociety Aadhaar  To generate the password the...\n",
       "                                ...                        \n",
       "205358    How Modi Has Trampled the Founding Idea of Ind...\n",
       "205359    Jaipur Police takes a potshot at Masakali 20 ‘...\n",
       "205360    When do u think international flights will res...\n",
       "205361                         Kangna Vilayati Song Lyrics \n",
       "205362    What do you guys know about girish nanavati an...\n",
       "Name: text, Length: 203541, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "df_n, df_test = model_selection.train_test_split(\n",
    "        df,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=df.flair.values\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9d68f39978>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test.flair.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count            162832\n",
       "unique                7\n",
       "top       Non-Political\n",
       "freq              55420\n",
       "Name: flair, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n.flair.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n.to_csv('reddit_model_train_valid.csv', index=False)\n",
    "df_test.to_csv('reddit_model_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 10\n",
    "BERT_PATH = \"./bert_uncased/\"\n",
    "MODEL_PATH = \"app/model.bin\"\n",
    "TRAINING_FILE = \"reddit_model_train_valid.csv\"\n",
    "TOKENIZER = transformers.BertTokenizer.from_pretrained(\n",
    "    BERT_PATH,\n",
    "    do_lower_case=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Coronavirus', 'Politics', 'Non-Political', 'AskIndia',\n",
       "       'Policy/Economy', 'Science/Technology', 'Business/Finance'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfx = pd.read_csv(TRAINING_FILE).fillna(\"none\")\n",
    "dfx.flair.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180763 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(dfx['text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (162832, 512)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(dfx['text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (162832, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y = pd.get_dummies(dfx['flair']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146548, 512) (146548, 7)\n",
      "(16284, 512) (16284, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 512, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 512, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 5,081,107\n",
      "Trainable params: 5,081,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 117238 samples, validate on 29310 samples\n",
      "Epoch 1/6\n",
      "117238/117238 [==============================] - 524s 4ms/step - loss: 0.7146 - accuracy: 0.7475 - val_loss: 0.8313 - val_accuracy: 0.7066\n",
      "Epoch 2/6\n",
      "117238/117238 [==============================] - 520s 4ms/step - loss: 0.6557 - accuracy: 0.7668 - val_loss: 0.8636 - val_accuracy: 0.6976\n",
      "Epoch 3/6\n",
      "117238/117238 [==============================] - 512s 4ms/step - loss: 0.6031 - accuracy: 0.7868 - val_loss: 0.9026 - val_accuracy: 0.6871\n",
      "Epoch 4/6\n",
      "117238/117238 [==============================] - 507s 4ms/step - loss: 0.5548 - accuracy: 0.8036 - val_loss: 0.9667 - val_accuracy: 0.6794\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 6\n",
    "batch_size = 256\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AskIndia</th>\n",
       "      <th>Business/Finance</th>\n",
       "      <th>Coronavirus</th>\n",
       "      <th>Non-Political</th>\n",
       "      <th>Policy/Economy</th>\n",
       "      <th>Politics</th>\n",
       "      <th>Science/Technology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AskIndia  Business/Finance  Coronavirus  Non-Political  Policy/Economy  \\\n",
       "0         0                 0            1              0               0   \n",
       "1         0                 0            0              0               0   \n",
       "2         0                 0            0              0               0   \n",
       "3         0                 0            0              1               0   \n",
       "4         1                 0            0              0               0   \n",
       "5         0                 0            0              0               0   \n",
       "6         0                 0            0              0               1   \n",
       "7         0                 0            0              0               0   \n",
       "8         0                 0            0              0               0   \n",
       "9         0                 0            0              0               0   \n",
       "\n",
       "   Politics  Science/Technology  \n",
       "0         0                   0  \n",
       "1         1                   0  \n",
       "2         1                   0  \n",
       "3         0                   0  \n",
       "4         0                   0  \n",
       "5         1                   0  \n",
       "6         0                   0  \n",
       "7         1                   0  \n",
       "8         1                   0  \n",
       "9         1                   0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = pd.get_dummies(dfx['flair'])\n",
    "Y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16284/16284 [==============================] - 41s 3ms/step\n",
      "Test set\n",
      "  Loss: 1.098\n",
      "  Accuracy: 0.650\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.097719028815389, 0.6500245928764343]\n"
     ]
    }
   ],
   "source": [
    "print(accr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"lstm_no_glove.json\", \"w\") as json_file:\n",
    "\tjson_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"lstm_no_glove.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 180763 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 50\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(dfx['text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vectors...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "# load in pre-trained word vectors\n",
    "print('Loading word vectors...')\n",
    "word2vec = {}\n",
    "with open(os.path.join('glove.6B.%sd.txt' % EMBEDDING_DIM)) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling pre-trained embeddings...\n"
     ]
    }
   ],
   "source": [
    "# prepare embedding matrix\n",
    "print('Filling pre-trained embeddings...')\n",
    "num_words = min(MAX_NB_WORDS, len(word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "  if i < MAX_NB_WORDS:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector\n",
    "\n",
    "\n",
    "\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(\n",
    "  num_words,\n",
    "  EMBEDDING_DIM,\n",
    "  weights=[embedding_matrix],\n",
    "  input_length=MAX_SEQUENCE_LENGTH,\n",
    "  trainable=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ba4c4ea81db6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minput_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_SEQUENCE_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "input_ = Input(shape=(MAX_SEQUENCE_LENGTH,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 500, 50)           2500000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 500, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 707       \n",
      "=================================================================\n",
      "Total params: 2,561,107\n",
      "Trainable params: 61,107\n",
      "Non-trainable params: 2,500,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (162832, 500)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(dfx['text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (162832, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y = pd.get_dummies(dfx['flair']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(146548, 500) (146548, 7)\n",
      "(16284, 500) (16284, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 117238 samples, validate on 29310 samples\n",
      "Epoch 1/6\n",
      " 84480/117238 [====================>.........] - ETA: 1:38 - loss: 1.3431 - accuracy: 0.5013"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs = 6\n",
    "batch_size = 256\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"lstm_glove.json\", \"w\") as json_file:\n",
    "\tjson_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"lstm_glove.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class BERTDataset:\n",
    "    def __init__(self, text, flair):\n",
    "        self.text = text\n",
    "        self.flair = flair\n",
    "        self.tokenizer = TOKENIZER\n",
    "        self.max_len = MAX_LEN\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.text[item])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True\n",
    "        )\n",
    "\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.flair[item], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def loss_fn(outputs, targets):\n",
    "    return nn.CrossEntropyLoss()(outputs, targets.view(-1, 1))\n",
    "\n",
    "\n",
    "def train_fn(data_loader, model, optimizer, device, scheduler):\n",
    "    model.train()\n",
    "\n",
    "    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ids = d[\"ids\"]\n",
    "        token_type_ids = d[\"token_type_ids\"]\n",
    "        mask = d[\"mask\"]\n",
    "        targets = d[\"targets\"]\n",
    "\n",
    "        ids = ids.to(device, dtype=torch.long)\n",
    "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "        mask = mask.to(device, dtype=torch.long)\n",
    "        targets = targets.to(device, dtype=torch.float)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            ids=ids,\n",
    "            mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "\n",
    "def eval_fn(data_loader, model, device):\n",
    "    model.eval()\n",
    "    fin_targets = []\n",
    "    fin_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            ids = d[\"ids\"]\n",
    "            token_type_ids = d[\"token_type_ids\"]\n",
    "            mask = d[\"mask\"]\n",
    "            targets = d[\"targets\"]\n",
    "\n",
    "            ids = ids.to(device, dtype=torch.long)\n",
    "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
    "            mask = mask.to(device, dtype=torch.long)\n",
    "            targets = targets.to(device, dtype=torch.long)\n",
    "\n",
    "            outputs = model(\n",
    "                ids=ids,\n",
    "                mask=mask,\n",
    "                token_type_ids=token_type_ids\n",
    "            )\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
    "    return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class BERTBaseUncased(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTBaseUncased, self).__init__()\n",
    "        self.bert = transformers.BertModel.from_pretrained(BERT_PATH)\n",
    "        self.bert_drop = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(768, 7)\n",
    "    \n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, o2 = self.bert(\n",
    "            ids, \n",
    "            attention_mask=mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        bo = self.bert_drop(o2)\n",
    "        output = self.out(bo)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Coronavirus', 'Politics', 'Non-Political', 'AskIndia',\n",
       "       'Policy/Economy', 'Science/Technology', 'Business/Finance'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfx = pd.read_csv(TRAINING_FILE).fillna(\"none\")\n",
    "dfx.flair.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AskIndia' 'Business/Finance' 'Coronavirus' 'Non-Political'\n",
      " 'Policy/Economy' 'Politics' 'Science/Technology']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "dfx['flair'] = le.fit_transform(dfx.flair.values)\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 3.81 GiB total capacity; 2.56 GiB already allocated; 65.75 MiB free; 2.60 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a0ddcff3027a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-a0ddcff3027a>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     )\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, module, device_ids, output_device, dim)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 90.00 MiB (GPU 0; 3.81 GiB total capacity; 2.56 GiB already allocated; 65.75 MiB free; 2.60 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "def run():\n",
    "    df_train, df_valid = model_selection.train_test_split(\n",
    "        dfx,\n",
    "        test_size=0.1,\n",
    "        random_state=42,\n",
    "        stratify=dfx.flair.values\n",
    "    )\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_valid = df_valid.reset_index(drop=True)\n",
    "\n",
    "    train_dataset = BERTDataset(\n",
    "        text=df_train.text.values,\n",
    "        flair=df_train.flair.values\n",
    "    )\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=TRAIN_BATCH_SIZE,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    valid_dataset = BERTDataset(\n",
    "        text=df_valid.text.values,\n",
    "        flair=df_valid.flair.values\n",
    "    )\n",
    "\n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=VALID_BATCH_SIZE,\n",
    "        num_workers=1\n",
    "    )\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = BERTBaseUncased()\n",
    "    torch.cuda.empty_cache()  # entirely clear all allocated memory\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    ]\n",
    "\n",
    "    num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=3e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_train_steps\n",
    "    )\n",
    "\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "    best_accuracy = 0\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_fn(train_data_loader, model, optimizer, device, scheduler)\n",
    "        outputs, targets = eval_fn(valid_data_loader, model, device)\n",
    "        outputs = np.array(outputs) >= 0.5\n",
    "        accuracy = metrics.accuracy_score(targets, outputs)\n",
    "        print(f\"Accuracy Score = {accuracy}\")\n",
    "        if accuracy > best_accuracy:\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            best_accuracy = accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
